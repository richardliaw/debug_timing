{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 Workers - no tp\n",
    "```\n",
    "Total time: 39.0863 s\n",
    "File: driver.py\n",
    "Function: train at line 69\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "    69                                           def train(num_workers, env_name=\"PongDeterministic-v3\"):\n",
    "    70         1        33528  33528.0      0.1    env = create_env(env_name)\n",
    "    71         1      1440049 1440049.0      3.7    ps = ParameterServer(env)\n",
    "    72         1            5      5.0      0.0    parameters = ps.get_weights()\n",
    "    73         1        43683  43683.0      0.1    agents = [Runner.remote(env_name, i) for i in range(num_workers)]\n",
    "    74         1            3      3.0      0.0    delta_list = [agent.get_delta.remote(parameters)\n",
    "    75         1        27090  27090.0      0.1                     for agent in agents]\n",
    "    76         1           11     11.0      0.0    steps = 0\n",
    "    77         1           11     11.0      0.0    obs = 0\n",
    "    78         1            6      6.0      0.0    timing = []\n",
    "    79      2001        10263      5.1      0.0    for i in range(2000):\n",
    "    80      2000     22779774  11389.9     58.3      done_id, delta_list = ray.wait(delta_list)\n",
    "    81      2000      1470236    735.1      3.8      delta, info = ray.get(done_id)[0]\n",
    "    82      2000      5553732   2776.9     14.2      ps.add_delta(delta)\n",
    "    83      2000       202255    101.1      0.5      parameters = ps.weights\n",
    "    84      2000         8298      4.1      0.0      obs += info[\"size\"]\n",
    "    85      2000         6311      3.2      0.0      delta_list.extend(\n",
    "    86      2000      7511039   3755.5     19.2          [agents[info[\"id\"]].get_delta.remote(parameters)])\n",
    "    87         1           27     27.0      0.0    return ps.get_policy()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16 Workers - no tp\n",
    "```\n",
    "Total time: 26.8567 s\n",
    "File: driver.py\n",
    "Function: train at line 69\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "    69                                           def train(num_workers, env_name=\"PongDeterministic-v3\"):\n",
    "    70         1        33746  33746.0      0.1    env = create_env(env_name)\n",
    "    71         1      1438450 1438450.0      5.4    ps = ParameterServer(env)\n",
    "    72         1            6      6.0      0.0    parameters = ps.get_weights()\n",
    "    73         1        78307  78307.0      0.3    agents = [Runner.remote(env_name, i) for i in range(num_workers)]\n",
    "    74         1            5      5.0      0.0    delta_list = [agent.get_delta.remote(parameters)\n",
    "    75         1       305121 305121.0      1.1                     for agent in agents]\n",
    "    76         1            5      5.0      0.0    steps = 0\n",
    "    77         1            2      2.0      0.0    obs = 0\n",
    "    78         1            3      3.0      0.0    timing = []\n",
    "    79      2001        10741      5.4      0.0    for i in range(2000):\n",
    "    80      2000     11217581   5608.8     41.8      done_id, delta_list = ray.wait(delta_list)\n",
    "    81      2000      1476732    738.4      5.5      delta, info = ray.get(done_id)[0]\n",
    "    82      2000      5447272   2723.6     20.3      ps.add_delta(delta)\n",
    "    83      2000       127134     63.6      0.5      parameters = ps.weights\n",
    "    84      2000         9399      4.7      0.0      obs += info[\"size\"]\n",
    "    85      2000         6756      3.4      0.0      delta_list.extend(\n",
    "    86      2000      6705390   3352.7     25.0          [agents[info[\"id\"]].get_delta.remote(parameters)])\n",
    "    87         1           19     19.0      0.0    return ps.get_policy()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 Workers - no tp\n",
    "```\n",
    "Total time: 23.7292 s\n",
    "File: driver.py\n",
    "Function: train at line 69\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "    69                                           def train(num_workers, env_name=\"PongDeterministic-v3\"):\n",
    "    70         1        35069  35069.0      0.1    env = create_env(env_name)\n",
    "    71         1      1504657 1504657.0      6.3    ps = ParameterServer(env)\n",
    "    72         1            8      8.0      0.0    parameters = ps.get_weights()\n",
    "    73         1       158049 158049.0      0.7    agents = [Runner.remote(env_name, i) for i in range(num_workers)]\n",
    "    74         1            8      8.0      0.0    delta_list = [agent.get_delta.remote(parameters)\n",
    "    75         1       358418 358418.0      1.5                     for agent in agents]\n",
    "    76         1            8      8.0      0.0    steps = 0\n",
    "    77         1            2      2.0      0.0    obs = 0\n",
    "    78         1            2      2.0      0.0    timing = []\n",
    "    79      2001        11497      5.7      0.0    for i in range(2000):\n",
    "    80      2000      4490992   2245.5     18.9      done_id, delta_list = ray.wait(delta_list)\n",
    "    81      2000      1701133    850.6      7.2      delta, info = ray.get(done_id)[0]\n",
    "    82      2000      7163186   3581.6     30.2      ps.add_delta(delta)\n",
    "    83      2000       428046    214.0      1.8      parameters = ps.weights\n",
    "    84      2000         9911      5.0      0.0      obs += info[\"size\"]\n",
    "    85      2000         7820      3.9      0.0      delta_list.extend(\n",
    "    86      2000      7860349   3930.2     33.1          [agents[info[\"id\"]].get_delta.remote(parameters)])\n",
    "    87         1           32     32.0      0.0    return ps.get_policy()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More specific profiling: \n",
    "```\n",
    "   Ordered by: internal time\n",
    "   List reduced from 59 to 20 due to restriction <20>\n",
    "\n",
    "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
    "     2000    7.147    0.004    7.147    0.004 /home/ubuntu/a3c/misc.py:19(<dictcomp>)\n",
    "     2000    6.697    0.003    6.697    0.003 {built-in method ray.core.src.numbuf.libnumbuf.store_list}\n",
    "     2000    4.008    0.002    4.008    0.002 {built-in method ray.core.src.plasma.libplasma.wait}\n",
    "     2000    0.872    0.000    0.872    0.000 {built-in method ray.core.src.numbuf.libnumbuf.retrieve_list}\n",
    "    16000    0.182    0.000    0.272    0.000 /home/ubuntu/.local/lib/python3.5/site-packages/ray-0.0.1-py3.5.egg/ray/worker.py:1747(log)\n",
    "     2000    0.174    0.000    7.411    0.004 /home/ubuntu/.local/lib/python3.5/site-packages/ray-0.0.1-py3.5.egg/ray/worker.py:645(submit_task)\n",
    "     2000    0.110    0.000    1.089    0.001 /home/ubuntu/.local/lib/python3.5/site-packages/ray-0.0.1-py3.5.egg/ray/worker.py:589(get_object)\n",
    "     2000    0.077    0.000    0.077    0.000 {method 'compute_put_id' of 'local_scheduler.LocalSchedulerClient' objects}\n",
    "     2000    0.077    0.000    4.388    0.002 /home/ubuntu/.local/lib/python3.5/site-packages/ray-0.0.1-py3.5.egg/ray/worker.py:1841(wait)\n",
    "     2000    0.072    0.000    7.050    0.004 /home/ubuntu/.local/lib/python3.5/site-packages/ray-0.0.1-py3.5.egg/ray/worker.py:1818(put)\n",
    "    10000    0.066    0.000    0.157    0.000 /home/ubuntu/.local/lib/python3.5/site-packages/ray-0.0.1-py3.5.egg/ray/worker.py:784(check_main_thread)\n",
    "     2000    0.066    0.000    7.676    0.004 /home/ubuntu/.local/lib/python3.5/site-packages/ray-0.0.1-py3.5.egg/ray/actor.py:286(actor_method_call)\n",
    "6000/2000    0.059    0.000    0.061    0.000 /home/ubuntu/.local/lib/python3.5/site-packages/ray-0.0.1-py3.5.egg/ray/actor.py:374(__getattribute__)\n",
    "     2000    0.055    0.000    0.059    0.000 /home/ubuntu/.local/lib/python3.5/site-packages/ray-0.0.1-py3.5.egg/ray/signature.py:118(extend_args)\n",
    "     2000    0.054    0.000    4.066    0.002 /home/ubuntu/.local/lib/python3.5/site-packages/ray-0.0.1-py3.5.egg/ray/plasma/plasma.py:273(wait)\n",
    "     8000    0.053    0.000    0.071    0.000 /home/ubuntu/.local/lib/python3.5/site-packages/ray-0.0.1-py3.5.egg/ray/worker.py:1739(log_span)\n",
    "     2000    0.052    0.000    0.052    0.000 {built-in method ray.core.src.plasma.libplasma.fetch}\n",
    "     2000    0.050    0.000    1.256    0.001 /home/ubuntu/.local/lib/python3.5/site-packages/ray-0.0.1-py3.5.egg/ray/worker.py:1780(get)\n",
    "     2000    0.043    0.000    0.084    0.000 /home/ubuntu/.local/lib/python3.5/site-packages/ray-0.0.1-py3.5.egg/ray/actor.py:27(get_actor_method_function_id)\n",
    "     2000    0.040    0.000    0.040    0.000 {method 'submit' of 'local_scheduler.LocalSchedulerClient' objects}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24 Workers - no tp\n",
    "```\n",
    "Total time: 25.4854 s\n",
    "File: driver.py\n",
    "Function: train at line 69\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "    69                                           def train(num_workers, env_name=\"PongDeterministic-v3\"):\n",
    "    70         1        33762  33762.0      0.1    env = create_env(env_name)\n",
    "    71         1      1470920 1470920.0      5.8    ps = ParameterServer(env)\n",
    "    72         1            9      9.0      0.0    parameters = ps.get_weights()\n",
    "    73         1       333468 333468.0      1.3    agents = [Runner.remote(env_name, i) for i in range(num_workers)]\n",
    "    74         1            8      8.0      0.0    delta_list = [agent.get_delta.remote(parameters)\n",
    "    75         1       391634 391634.0      1.5                     for agent in agents]\n",
    "    76         1            3      3.0      0.0    steps = 0\n",
    "    77         1            1      1.0      0.0    obs = 0\n",
    "    78         1            1      1.0      0.0    timing = []\n",
    "    79      2001        16787      8.4      0.1    for i in range(2000):\n",
    "    80      2000      4167318   2083.7     16.4      done_id, delta_list = ray.wait(delta_list)\n",
    "    81      2000      1985166    992.6      7.8      delta, info = ray.get(done_id)[0]\n",
    "    82      2000      7101292   3550.6     27.9      ps.add_delta(delta)\n",
    "    83      2000        93660     46.8      0.4      parameters = ps.weights\n",
    "    84      2000        10274      5.1      0.0      obs += info[\"size\"]\n",
    "    85      2000         8707      4.4      0.0      delta_list.extend(\n",
    "    86      2000      9872327   4936.2     38.7          [agents[info[\"id\"]].get_delta.remote(parameters)])\n",
    "    87         1           19     19.0      0.0    return ps.get_policy()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
