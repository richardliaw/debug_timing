{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 Workers - no tp\n",
    "```\n",
    "Total time: 39.0863 s\n",
    "File: driver.py\n",
    "Function: train at line 69\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "    69                                           def train(num_workers, env_name=\"PongDeterministic-v3\"):\n",
    "    70         1        33528  33528.0      0.1    env = create_env(env_name)\n",
    "    71         1      1440049 1440049.0      3.7    ps = ParameterServer(env)\n",
    "    72         1            5      5.0      0.0    parameters = ps.get_weights()\n",
    "    73         1        43683  43683.0      0.1    agents = [Runner.remote(env_name, i) for i in range(num_workers)]\n",
    "    74         1            3      3.0      0.0    delta_list = [agent.get_delta.remote(parameters)\n",
    "    75         1        27090  27090.0      0.1                     for agent in agents]\n",
    "    76         1           11     11.0      0.0    steps = 0\n",
    "    77         1           11     11.0      0.0    obs = 0\n",
    "    78         1            6      6.0      0.0    timing = []\n",
    "    79      2001        10263      5.1      0.0    for i in range(2000):\n",
    "    80      2000     22779774  11389.9     58.3      done_id, delta_list = ray.wait(delta_list)\n",
    "    81      2000      1470236    735.1      3.8      delta, info = ray.get(done_id)[0]\n",
    "    82      2000      5553732   2776.9     14.2      ps.add_delta(delta)\n",
    "    83      2000       202255    101.1      0.5      parameters = ps.weights\n",
    "    84      2000         8298      4.1      0.0      obs += info[\"size\"]\n",
    "    85      2000         6311      3.2      0.0      delta_list.extend(\n",
    "    86      2000      7511039   3755.5     19.2          [agents[info[\"id\"]].get_delta.remote(parameters)])\n",
    "    87         1           27     27.0      0.0    return ps.get_policy()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16 Workers - no tp\n",
    "```\n",
    "Total time: 26.8567 s\n",
    "File: driver.py\n",
    "Function: train at line 69\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "    69                                           def train(num_workers, env_name=\"PongDeterministic-v3\"):\n",
    "    70         1        33746  33746.0      0.1    env = create_env(env_name)\n",
    "    71         1      1438450 1438450.0      5.4    ps = ParameterServer(env)\n",
    "    72         1            6      6.0      0.0    parameters = ps.get_weights()\n",
    "    73         1        78307  78307.0      0.3    agents = [Runner.remote(env_name, i) for i in range(num_workers)]\n",
    "    74         1            5      5.0      0.0    delta_list = [agent.get_delta.remote(parameters)\n",
    "    75         1       305121 305121.0      1.1                     for agent in agents]\n",
    "    76         1            5      5.0      0.0    steps = 0\n",
    "    77         1            2      2.0      0.0    obs = 0\n",
    "    78         1            3      3.0      0.0    timing = []\n",
    "    79      2001        10741      5.4      0.0    for i in range(2000):\n",
    "    80      2000     11217581   5608.8     41.8      done_id, delta_list = ray.wait(delta_list)\n",
    "    81      2000      1476732    738.4      5.5      delta, info = ray.get(done_id)[0]\n",
    "    82      2000      5447272   2723.6     20.3      ps.add_delta(delta)\n",
    "    83      2000       127134     63.6      0.5      parameters = ps.weights\n",
    "    84      2000         9399      4.7      0.0      obs += info[\"size\"]\n",
    "    85      2000         6756      3.4      0.0      delta_list.extend(\n",
    "    86      2000      6705390   3352.7     25.0          [agents[info[\"id\"]].get_delta.remote(parameters)])\n",
    "    87         1           19     19.0      0.0    return ps.get_policy()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 Workers - no tp\n",
    "```\n",
    "Total time: 23.7292 s\n",
    "File: driver.py\n",
    "Function: train at line 69\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "    69                                           def train(num_workers, env_name=\"PongDeterministic-v3\"):\n",
    "    70         1        35069  35069.0      0.1    env = create_env(env_name)\n",
    "    71         1      1504657 1504657.0      6.3    ps = ParameterServer(env)\n",
    "    72         1            8      8.0      0.0    parameters = ps.get_weights()\n",
    "    73         1       158049 158049.0      0.7    agents = [Runner.remote(env_name, i) for i in range(num_workers)]\n",
    "    74         1            8      8.0      0.0    delta_list = [agent.get_delta.remote(parameters)\n",
    "    75         1       358418 358418.0      1.5                     for agent in agents]\n",
    "    76         1            8      8.0      0.0    steps = 0\n",
    "    77         1            2      2.0      0.0    obs = 0\n",
    "    78         1            2      2.0      0.0    timing = []\n",
    "    79      2001        11497      5.7      0.0    for i in range(2000):\n",
    "    80      2000      4490992   2245.5     18.9      done_id, delta_list = ray.wait(delta_list)\n",
    "    81      2000      1701133    850.6      7.2      delta, info = ray.get(done_id)[0]\n",
    "    82      2000      7163186   3581.6     30.2      ps.add_delta(delta)\n",
    "    83      2000       428046    214.0      1.8      parameters = ps.weights\n",
    "    84      2000         9911      5.0      0.0      obs += info[\"size\"]\n",
    "    85      2000         7820      3.9      0.0      delta_list.extend(\n",
    "    86      2000      7860349   3930.2     33.1          [agents[info[\"id\"]].get_delta.remote(parameters)])\n",
    "    87         1           32     32.0      0.0    return ps.get_policy()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24 Workers - no tp\n",
    "```\n",
    "Total time: 25.4854 s\n",
    "File: driver.py\n",
    "Function: train at line 69\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "    69                                           def train(num_workers, env_name=\"PongDeterministic-v3\"):\n",
    "    70         1        33762  33762.0      0.1    env = create_env(env_name)\n",
    "    71         1      1470920 1470920.0      5.8    ps = ParameterServer(env)\n",
    "    72         1            9      9.0      0.0    parameters = ps.get_weights()\n",
    "    73         1       333468 333468.0      1.3    agents = [Runner.remote(env_name, i) for i in range(num_workers)]\n",
    "    74         1            8      8.0      0.0    delta_list = [agent.get_delta.remote(parameters)\n",
    "    75         1       391634 391634.0      1.5                     for agent in agents]\n",
    "    76         1            3      3.0      0.0    steps = 0\n",
    "    77         1            1      1.0      0.0    obs = 0\n",
    "    78         1            1      1.0      0.0    timing = []\n",
    "    79      2001        16787      8.4      0.1    for i in range(2000):\n",
    "    80      2000      4167318   2083.7     16.4      done_id, delta_list = ray.wait(delta_list)\n",
    "    81      2000      1985166    992.6      7.8      delta, info = ray.get(done_id)[0]\n",
    "    82      2000      7101292   3550.6     27.9      ps.add_delta(delta)\n",
    "    83      2000        93660     46.8      0.4      parameters = ps.weights\n",
    "    84      2000        10274      5.1      0.0      obs += info[\"size\"]\n",
    "    85      2000         8707      4.4      0.0      delta_list.extend(\n",
    "    86      2000      9872327   4936.2     38.7          [agents[info[\"id\"]].get_delta.remote(parameters)])\n",
    "    87         1           19     19.0      0.0    return ps.get_policy()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
